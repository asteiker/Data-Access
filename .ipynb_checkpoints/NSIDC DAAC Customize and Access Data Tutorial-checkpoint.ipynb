{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NSIDC DAAC Customize and Access Data Tutorial\n",
    "#### This tutorial will walk you though how to access NSIDC DAAC data using spatial and temporal filters, as well as how to request customization services including subsetting, reformatting, and reprojection. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, getpass, socket, pycurl, urllib.request, json, zipfile, io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a token\n",
    "\n",
    "We will generate a token needed in order to access data using your Earthdata Login credentials, and we will apply that token to the following queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earthdata Login user name: amy.steiker\n",
      "Earthdata Login password: ········\n"
     ]
    }
   ],
   "source": [
    "# Earthdata Login credentials\n",
    "\n",
    "uid = input('Earthdata Login user name: ')\n",
    "pswd = getpass.getpass('Earthdata Login password: ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to request token from Common Metadata Repository\n",
    "\n",
    "def create_token (uid, pswd):\n",
    "    \n",
    "    #import XML Element Tree\n",
    "    from xml.etree.ElementTree import Element, SubElement, Comment, tostring\n",
    "    \n",
    "    #Find IP address\n",
    "    hostname = socket.gethostname() \n",
    "    IP = socket.gethostbyname(hostname)\n",
    "    \n",
    "    #Create XML input\n",
    "\n",
    "    token = Element('token')\n",
    "    username = SubElement(token, 'username')\n",
    "    username.text = uid\n",
    "    password = SubElement(token, 'password')\n",
    "    password.text = pswd\n",
    "    client_id = SubElement(token, 'client_id')\n",
    "    client_id.text = 'NSIDC_client_id'\n",
    "    user_ip_address = SubElement(token, 'user_ip_address')\n",
    "    user_ip_address.text = IP\n",
    "\n",
    "    xml = (tostring(token, encoding='unicode', method='xml'))\n",
    "    \n",
    "    #Request token from Common Metadata Repository\n",
    "\n",
    "    headers = {'Content-Type': 'application/xml'} \n",
    "    token = requests.post('https://api.echo.nasa.gov/echo-rest/tokens', data=xml, headers=headers)\n",
    "    output = token.text\n",
    "    \n",
    "    #Grab token string\n",
    "\n",
    "    start = '<id>'\n",
    "    end = '</id>'\n",
    "\n",
    "    tokenval =(output.split(start))[1].split(end)[0]\n",
    "    \n",
    "    return tokenval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AC5DFB22-89B3-808E-BB0F-18960D364EFB\n"
     ]
    }
   ],
   "source": [
    "# Run create_token function using Earthdata Login Username (uid) and Password (pswd) as inputs\n",
    "\n",
    "token = create_token(uid, pswd)\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select a data set of interest and determine the number and size of granules available within a time range and location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's begin discovering an NSIDC DAAC data set by first inputting the data set of interest and determining the most recent version number. We will also find out how many data granules exist over an area and time of interest. The Common Metadata Repository is queried to explore this information.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input short name, e.g. ATL03, here: MOD10A1\n"
     ]
    }
   ],
   "source": [
    "# Input data set short name (e.g. ATL03) of interest here.\n",
    "\n",
    "short_name = input('Input short name, e.g. ATL03, here: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For restricted collections\n",
    "# First determine the latest verion number by querying CMR collection metadata.\n",
    "\n",
    "\n",
    "# mr_url = 'https://cmr.earthdata.nasa.gov/search/collections.json?short_name=' + short_name + '&token=' + token\n",
    "# cmeta = requests.get(cmr_url)\n",
    " \n",
    "# with urllib.request.urlopen(cmr_url) as url:\n",
    "#    cmeta_json = json.loads(url.read().decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most recent version of  MOD10A1  is  6\n"
     ]
    }
   ],
   "source": [
    "# Get json response from CMR collection metadata\n",
    "\n",
    "\n",
    "cmr_url = 'https://cmr.earthdata.nasa.gov/search/collections.json?short_name=' + short_name\n",
    "#cmeta = requests.get(cmr_url)\n",
    " \n",
    "with urllib.request.urlopen(cmr_url) as url:\n",
    "    cmeta_json = json.loads(url.read().decode())\n",
    "\n",
    "# Find all instances of 'version_id' in metadata and print most recent version number\n",
    "    \n",
    "entry = cmeta_json['feed']['entry']\n",
    "versions = []\n",
    "for x in range(len(entry)):\n",
    "    versions.append((entry[x]['version_id']))\n",
    "\n",
    "latest_version = max(versions)\n",
    "print('The most recent version of ', short_name, ' is ', latest_version)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we have the most recent version of this data set, let's determine the number of granules available over our area and time of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input lower left longitude in decimal degrees: -120.234234\n",
      "Input lower left latitude in decimal degrees: 40.23423\n",
      "Input upper right longitude in decimal degrees: -115.34234\n",
      "Input upper right latitude in decimal degrees: 42.23423\n"
     ]
    }
   ],
   "source": [
    "#https://cmr.earthdata.nasa.gov/search/granules?\n",
    "\n",
    "#Input bounding box\n",
    "\n",
    "LL_lon = input('Input lower left longitude in decimal degrees: ')\n",
    "LL_lat = input('Input lower left latitude in decimal degrees: ')\n",
    "UR_lon = input('Input upper right longitude in decimal degrees: ')\n",
    "UR_lat = input('Input upper right latitude in decimal degrees: ')\n",
    "\n",
    "bounding_box = LL_lon + ',' + LL_lat + ',' + UR_lon + ',' + UR_lat\n",
    "           \n",
    "#Maybe a way to upload a shapefile and output the coordinates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input start date in yyyy-MM-dd format: 2019-03-01\n",
      "Input start time in HH:mm:ss format: 00:00:00\n",
      "Input end date in yyyy-MM-dd format: 2019-03-20\n",
      "Input end time in HH:mm:ss format: 23:59:59\n"
     ]
    }
   ],
   "source": [
    "#Input temporal range \n",
    "\n",
    "start_date = input('Input start date in yyyy-MM-dd format: ')\n",
    "start_time = input('Input start time in HH:mm:ss format: ')\n",
    "end_date = input('Input end date in yyyy-MM-dd format: ')\n",
    "end_time = input('Input end time in HH:mm:ss format: ')\n",
    "\n",
    "temporal = start_date + 'T' + start_time + 'Z' + ',' + end_date + 'T' + end_time + 'Z'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 40 granules of MOD10A1 version 6 over my area and time of interest.\n"
     ]
    }
   ],
   "source": [
    "#find number of granules\n",
    "\n",
    "granule_params = {'short_name': short_name, 'version': latest_version, 'bounding_box': bounding_box, 'temporal': temporal}\n",
    "cmr_granule = requests.get('https://cmr.earthdata.nasa.gov/search/granules', params=granule_params)\n",
    " \n",
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "root = ET.fromstring(cmr_granule.content)\n",
    "ET.tostring(root, encoding='utf8').decode('utf8')\n",
    "hit_val = []\n",
    "for hits in root.iter('hits'):\n",
    "    hit_val.append(hits.text)\n",
    "\n",
    "print('There are', hit_val[0], 'granules of', short_name, 'version', latest_version, 'over my area and time of interest.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will now query the average size of those granules as well as the total volume. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average size of each granule is 4.546394425 MB and the total size of all  40 granules is 181.85577700000002 MB\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "\n",
    "# Get json response from CMR granule metadata\n",
    "\n",
    "#Need to consider a case where hits > 2000 since this is the limit of CMR page_size (need to consider loop)\n",
    "\n",
    "granule_url = 'https://cmr.earthdata.nasa.gov/search/granules.json?short_name=' + short_name + '&version=' + latest_version + '&bounding_box=' + bounding_box + '&temporal=' + temporal + '&page_size=' + hit_val[0]\n",
    "\n",
    "with urllib.request.urlopen(granule_url) as url:\n",
    "    gmeta_json = json.loads(url.read().decode())\n",
    "\n",
    "# Find all instances of 'granule_size' in metadata and print average and total size\n",
    "    \n",
    "entry = gmeta_json['feed']['entry']\n",
    "size = []\n",
    "for x in range(len(entry)):\n",
    "    size.append(float((entry[x]['granule_size'])))\n",
    "\n",
    "# print average and total granule size\n",
    "    \n",
    "print('The average size of each granule is', mean(size), 'MB and the total size of all ', hit_val[0], 'granules is', sum(size), 'MB')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Although subsetting, reformatting, or reprojecting can alter the size of the granules, this \"native\" granule size can still be used to guide us towards the best download method to pursue, which we will come back to later on in this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine the subsetting, reformatting, and reprojection services enabled for your data set of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The NSIDC DAAC supports customization services on many of our NASA Earthdata mission collections. Let's discover if our data set has these services available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'HEG', 'spatialSubsetting': 'true', 'temporalSubsetting': 'false', 'type': 'both', 'maxGransSyncRequest': '100', 'maxGransAsyncRequest': '2000'}\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Query service capability URL \n",
    "\n",
    "capability_url = 'https://n5eil02u.ecs.nsidc.org/egi/capabilities/' + short_name + '.' + latest_version + '.xml'\n",
    "\n",
    "capability = requests.get(capability_url)\n",
    "\n",
    "\n",
    "root = ET.fromstring(capability.content)\n",
    "#print(ET.tostring(root, encoding='utf8').decode('utf8'))\n",
    "\n",
    "subagent = []\n",
    "for SubsetAgent in root.iter('SubsetAgent'):\n",
    "    subagent.append(SubsetAgent.attrib)\n",
    "    \n",
    "if len(subagent) < 1 :\n",
    "    print('No services exist for', short_name, 'version', latest_version)\n",
    "else:\n",
    "    subdict = subagent[0]\n",
    "    print(subdict)\n",
    "    print(subdict['spatialSubsetting'] == 'true')\n",
    "    print(subdict['temporalSubsetting'] == 'true')\n",
    "\n",
    "    \n",
    "\n",
    "#response = requests.get(capability_url)\n",
    "#root = ElementTree.fromstring(response.content)\n",
    "\n",
    "#SubsetAgent in root.iter('SubsetAgent')\n",
    "\n",
    "#for SubsetAgent in root.iter('SubsetAgent'):\n",
    "#    print(SubsetAgent.attrib)\n",
    "\n",
    "    \n",
    "#Print Spatial subsetting available? Yes/no, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#for SubsetAgent in root.findall('SubsetAgent'):\n",
    "#    print(id)\n",
    "\n",
    "#'SubsetAgent' in child.tagroot.iter('*')\n",
    "\n",
    "#if not child in root.iter('SubAgent'):\n",
    "#    print('No customization services exist for', short_name, 'version', latest_version)\n",
    "#else: \n",
    "#    for child in root.iter('SubAgent'):\n",
    "#        print(child.attrib['*'])\n",
    "\n",
    "\n",
    "#for child in root.iter('SubAgent'):\n",
    "#    print(child.attrib['*'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For data sets with the services we just queried, let's explore the specific service options available for this data set and select which of these services we want to request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from xml.etree import ElementTree\n",
    "\n",
    "response = requests.get(capability_url)\n",
    "root = ElementTree.fromstring(response.content)\n",
    "for child in root.iter('Format'):\n",
    "    print(child.attrib['value'])\n",
    "\n",
    "    \n",
    "#User input: Do you want reformatting? If so, select __ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose request method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two main access methods that the NSIDC DAAC supports through our Application Programming Interface (API).\n",
    "\n",
    "The first is synchronous: The data request is processed on the fly. Upon completion, data are downloaded directly to this directory as a single zip file. \n",
    "\n",
    "The second method is asynchronous: The data request is processed at NSIDC and sent to you via email. The email contains zip file(s) and a link to the order information, along with individual output download links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we download, we need to determine the max number of sync granules\n",
    "\n",
    "# \n",
    "\n",
    "\n",
    "# Download data test (still in progress)\n",
    "\n",
    "\n",
    "# base URL: https://n5eil02u.ecs.nsidc.org/egi/request?\n",
    "# short_name=GLAH12\n",
    "# version=034\n",
    "# bounding_box=-50.33333,68.56667,-49.33333,69.56667\n",
    "# bbox=-50.33333,68.56667,-49.33333,69.56667\n",
    "# time=2009-01-01T00:00:00,2009-12-31T23:59:59\n",
    "# format=TABULAR_ASCII\n",
    "# token=TOKEN-FROM-STEP-2\n",
    "\n",
    "access_url = 'https://n5eil02u.ecs.nsidc.org/egi/request?' + 'short_name=GLAH12&' + 'version=034&' + 'bounding_box=-50.33333,68.56667,-49.33333,69.56667&' + 'bbox=-50.33333,68.56667,-49.33333,69.56667&' + 'time=2009-01-01T00:00:00,2009-12-31T23:59:59&' + 'format=TABULAR_ASCII&' + 'token=' + token\n",
    "print(access_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(access_url, allow_redirects=True)\n",
    "#open('google.ico', 'wb').write(r.content)\n",
    "#resp = requests.get(\"http://www.example.com\", \n",
    "                    #params = {\"name\":\"Daniel\", \"id\": 123456})\n",
    "    \n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "z.extractall()\n",
    "\n",
    "\n",
    "#with open(\"data_output\",'wb') as f: \n",
    "  \n",
    "    # Saving received content as a png file in \n",
    "    # binary format \n",
    "  \n",
    "    # write the contents of the response (r.content) \n",
    "    # to a new file in binary mode. \n",
    "    #f.write(r.content) \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
